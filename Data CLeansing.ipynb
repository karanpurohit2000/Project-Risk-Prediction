{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0269dfa9-6a3b-469a-af43-7441db97e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c6673cc-ddc0-4c4e-8e82-847e3ee3cc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training script...\n",
      "Data loaded successfully from 'project_risk_data.csv'\n",
      "Dataset shape: (500, 12)\n",
      "First 5 rows of data:\n",
      "  project_id  project_complexity  num_overdue_tasks  num_assignees  \\\n",
      "0   PROJ_001                 152                 41             17   \n",
      "1   PROJ_002                 485                 69              4   \n",
      "2   PROJ_003                 398                 14              1   \n",
      "3   PROJ_004                 320                 53              8   \n",
      "4   PROJ_005                 156                 59             17   \n",
      "\n",
      "   owner_success_rate  planned_duration_days  daily_task_updates  \\\n",
      "0                0.78                     31                 2.5   \n",
      "1                0.74                    106                 1.0   \n",
      "2                0.94                    161                 3.5   \n",
      "3                0.77                    119                 5.0   \n",
      "4                0.72                    118                 3.8   \n",
      "\n",
      "   initial_budget_usd  project_delayed  start_date    due_date actual_end_date  \n",
      "0               18283                0  2023-08-22  2023-09-22      2023-09-22  \n",
      "1               68922                1  2023-08-09  2023-11-23      2023-12-09  \n",
      "2               44420                0  2023-11-19  2024-04-28      2024-04-26  \n",
      "3               60568                0  2023-12-05  2024-04-02      2024-03-31  \n",
      "4               90090                1  2023-01-03  2023-05-01      2023-05-07  \n"
     ]
    }
   ],
   "source": [
    "print(\"Starting model training script...\")\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "# Ensure 'project_risk_data.csv' is in the same directory as this script\n",
    "try:\n",
    "    df = pd.read_csv('project_risk_data.csv')\n",
    "    print(\"Data loaded successfully from 'project_risk_data.csv'\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(\"First 5 rows of data:\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'project_risk_data.csv' not found.\")\n",
    "    print(\"Please ensure you have run the data generation script and the CSV file is in the correct directory.\")\n",
    "    exit() # Exit if data is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bc636d8-6fa7-4032-9d34-6036a14bbd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropped columns: ['project_id', 'start_date', 'due_date', 'actual_end_date']\n",
      "Processed data shape: (500, 8)\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Data Cleaning and Preprocessing ---\n",
    "\n",
    "# Drop identifier columns not used for training\n",
    "# 'project_id' is just an identifier and should not be used as a feature.\n",
    "# 'start_date', 'due_date', 'actual_end_date' are used to derive 'project_delayed'\n",
    "# but not directly as features for the model in this simplified example.\n",
    "# In a real scenario, features like 'days_remaining_until_due' could be engineered.\n",
    "features_to_drop = ['project_id', 'start_date', 'due_date', 'actual_end_date']\n",
    "df_processed = df.drop(columns=features_to_drop, errors='ignore')\n",
    "\n",
    "print(f\"\\nDropped columns: {features_to_drop}\")\n",
    "print(f\"Processed data shape: {df_processed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f86c6400-14bb-430a-b1d2-2f247d4e2132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (synthetic data should be clean, but good practice)\n",
    "if df_processed.isnull().sum().sum() > 0:\n",
    "    print(\"\\nWarning: Missing values found. Imputing with median.\")\n",
    "    for col in df_processed.columns:\n",
    "        if df_processed[col].isnull().any():\n",
    "            if pd.api.types.is_numeric_dtype(df_processed[col]):\n",
    "                df_processed[col] = df_processed[col].fillna(df_processed[col].median())\n",
    "            else: # For categorical, fill with mode or a placeholder\n",
    "                df_processed[col] = df_processed[col].fillna(df_processed[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1359ef3b-fee8-4a10-b057-f1ac6cabc195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "# The target variable is 'project_delayed'\n",
    "X = df_processed.drop('project_delayed', axis=1)\n",
    "y = df_processed['project_delayed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13fa9d3a-d9cf-4ef8-a911-75dfd2875114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features (X) shape: (500, 7)\n",
      "Target (y) shape: (500,)\n",
      "Features used for training:\n",
      "['project_complexity', 'num_overdue_tasks', 'num_assignees', 'owner_success_rate', 'planned_duration_days', 'daily_task_updates', 'initial_budget_usd']\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFeatures (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "print(\"Features used for training:\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "229ffa20-002d-48ed-8ee9-0e3850bcc3b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set shape (X_train, y_train): (400, 7), (400,)\n",
      "Testing set shape (X_test, y_test): (100, 7), (100,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "# Using a stratify split to maintain the proportion of delayed/not delayed projects\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining set shape (X_train, y_train): {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set shape (X_test, y_test): {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d2d7488-af32-4678-84d8-e4c446c8ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "# It's crucial to fit the scaler ONLY on the training data to prevent data leakage.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) # Transform test data using the *fitted* scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d07435f0-3960-4fbd-9c1e-a3ec422eb7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to DataFrame for better readability (optional, but useful for inspection)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7cd9d9cc-e50a-4137-998f-14191731b651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForestClassifier model...\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Model Selection and Training ---\n",
    "# Using RandomForestClassifier for its robustness and good performance\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced') # 'balanced' helps with imbalanced classes\n",
    "print(f\"\\nTraining {type(model).__name__} model...\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c4a9423-30d8-4618-8131-f2bc9e4f5fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation ---\n",
      "Accuracy: 0.6500\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Not Delayed (0)       0.57      0.34      0.43        38\n",
      "    Delayed (1)       0.68      0.84      0.75        62\n",
      "\n",
      "       accuracy                           0.65       100\n",
      "      macro avg       0.62      0.59      0.59       100\n",
      "   weighted avg       0.63      0.65      0.63       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Evaluation ---\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1] # Probability of being delayed\n",
    "\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Not Delayed (0)', 'Delayed (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f808549b-e546-4248-bd5f-078c5790e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Save Model and Scaler ---\n",
    "# Create a 'models' directory if it doesn't exist\n",
    "models_dir = 'models'\n",
    "os.makedirs(models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e13a1a6a-5c5c-404d-b517-32e855860d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\feature_names.joblib']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.path.join(models_dir, 'random_forest_model.joblib')\n",
    "scaler_path = os.path.join(models_dir, 'scaler.joblib')\n",
    "feature_names_path = os.path.join(models_dir, 'feature_names.joblib')\n",
    "\n",
    "joblib.dump(model, model_path)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "joblib.dump(X.columns.tolist(), feature_names_path) # Save feature names for consistent input order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef4b7c9d-7c56-46dc-bf68-3b6a68ad9ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved to: models\\random_forest_model.joblib\n",
      "Scaler saved to: models\\scaler.joblib\n",
      "Feature names saved to: models\\feature_names.joblib\n",
      "\n",
      "Model training script finished.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nModel saved to: {model_path}\")\n",
    "print(f\"Scaler saved to: {scaler_path}\")\n",
    "print(f\"Feature names saved to: {feature_names_path}\")\n",
    "\n",
    "print(\"\\nModel training script finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b455b1a-cf7f-4b05-9375-c0ae652c69e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
